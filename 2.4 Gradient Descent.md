Gradient Descent can optimize:
![[Pasted image 20250609163301.png]]


![[Pasted image 20250609163412.png]]

We start by using *Gradient Descent* to find the **intercept**. We use the Least Squares estimate for the Slope, 0.64 -> use Gradient Descent for the intercept.

1. We pick a random value for the intercept. This is just an initial guess that gives Gradient Descent something to improve upon. We use 0 but any number is ok:
2. We will evaluate how well the line fits the data with the Sum of Squared Residuals
   ![[Pasted image 20250609163725.png]] ![[Pasted image 20250609163823.png]]
![[Pasted image 20250609163859.png]]
Predicted Height is 0.32
![[Pasted image 20250609163921.png]]

Residual = 1.4 - 0.32 = 1.1 (the residual)

![[Pasted image 20250609164111.png]]


![[Pasted image 20250609164206.png]]

Of the points that we calculated for the graph, the lowest point (the lowest Sum of Squared Residuals)
![[Pasted image 20250609164352.png]]

Gradient Descent 
- only does a few calculations far from the optimal solution and increases the number pf calculations closer to the optimal value
- identifies the optimal value by taking big steps when it is far away and baby steps when it is close.
![[Pasted image 20250609164631.png]]


![[Pasted image 20250609170336.png]]
![[Pasted image 20250609170355.png]]
![[Pasted image 20250609170405.png]]
![[Pasted image 20250609170420.png]]

![[Pasted image 20250609170509.png]]
![[Pasted image 20250609170530.png]]
!OBS: Gradient Descent stops when the Step Size is Very Close To 0. The Step Size will be very close to 0 when the Slope is very close to 0. In practice Minimum Step Size  = 0.001 or smaller. GD also includes a number of steps it will take before giving up (~ 1000 max steps)

**Step Size = Slope x Learning Rate**

**Gradient Descent** este un algoritm de optimizare folosit pentru **antrenarea modelelor de învățare automată**. Scopul său este de a **minimiza o funcție de cost** (de exemplu, eroarea dintre predicții și valori reale) prin ajustarea treptată a parametrilor modelului (cum ar fi $w_0$, $w_1$, etc.).

Este o metodă **iterativă** care merge „în jos” pe panta funcției (gradientul) până când ajunge într-un punct minim (ideal, un minim global).


#### Intuiția de bază

Imaginează-ți că ești pe un deal și vrei să ajungi în vale. Ai ochii închiși, dar poți simți înclinația terenului sub picioare. La fiecare pas, alegi direcția în care panta este cea mai abruptă în jos și faci un pas mic în acea direcție. Repeți acest proces până simți că nu mai cobori deloc.

Așa funcționează Gradient Descent: la fiecare iterație, ajustăm parametrii modelului în direcția opusă gradientului pentru a scădea valoarea funcției de cost.


### Cum funcționează concret?

Pentru un model, avem o **funcție de cost** $J(\mathbf{w})$ care depinde de parametrii $\mathbf{w} = [w_0, w_1, ..., w_n]$. Dorim să găsim valorile acestor coeficienți care **minimizează** funcția $J$.

La fiecare iterație, actualizăm coeficienții cu regula:

$w_j := w_j - \alpha \cdot \frac{\partial J(\mathbf{w})}{\partial w_j}$

Pentru toți $j = 0, 1, ..., n$, unde:

- $\alpha$ este **rata de învățare** (learning rate),
- $\frac{\partial J}{\partial w_j}$ este derivata parțială a funcției de cost față de coeficientul $w_j$ (adică gradientul).

### Ce este gradientul?

Gradientul este un **vector de derivate parțiale**, care indică direcția în care funcția de cost **crește cel mai repede**.
În Gradient Descent, folosim **direcția opusă** gradientului pentru a **scădea** valoarea funcției.
Pentru regresie liniară cu MSE, derivata este:

$\frac{\partial J(\mathbf{w})}{\partial w_j} = \frac{2}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)}) \cdot x_j^{(i)}$


### Rolul ratei de învățare $\alpha$

- Dacă $\alpha$ e **prea mic**, algoritmul învață lent, are nevoie de multe iterații.
- Dacă $\alpha$ e **prea mare**, algoritmul poate **sări peste minim** și chiar diverge.

## Tipuri de Gradient Descent

1. **Batch Gradient Descent**
    - Folosește **toate exemplele** pentru a calcula gradientul.
    - Update lent, dar direcția e stabilă.
    - Formula:  
        $\mathbf{w} := \mathbf{w} - \alpha \cdot \nabla J(\mathbf{w})$
2. **Stochastic Gradient Descent (SGD)**
    - Actualizează $\mathbf{w}$ **după fiecare exemplu**.
    - Mai rapid, dar introduce zgomot.
    - Ideal pentru seturi mari de date.
3. **Mini-batch Gradient Descent**
    - Compromis între batch și SGD.
    - Se împarte setul în loturi mici ("mini-batches") și se face update la fiecare lot.


### Convergență

- Se oprește când gradientul e aproape zero:  
    $\nabla J(\mathbf{w}) \approx \mathbf{0}$
- Sau când schimbările în funcția de cost sunt sub un prag foarte mic.

## Probleme comune

- **Rata de învățare nepotrivită**
- **Blocare în minime locale** (mai ales în rețele neuronale)
- **Platoșe**: zone unde gradientul este aproape zero pe o suprafață mare (progres foarte lent)