![[Pasted image 20250610180506.png]]
Dataset în stânga imaginii.![[Pasted image 20250610180537.png]]


Rețelele neuronale artificiale sunt modele inspirate din modul în care funcționează creierul uman. Sunt folosite în numeroase aplicații, inclusiv recunoaștere imagini, procesare limbaj natural, predicții, jocuri, și multe altele.

#### Inspirația biologică

- Un **neuron biologic** primește semnale de la alți neuroni, le procesează și transmite un impuls mai departe dacă semnalul este suficient de puternic.
- O **rețea neuronală artificială** are unități numite _neuroni artificiali_ sau _perceptroni_ care imită acest comportament.
#### Structura unei rețele neuronale

- **Strat de intrare**: preia vectorul de caracteristici (input)
- **Straturi ascunse**: unul sau mai multe, fiecare format din neuroni care aplică o funcție activare pe combinații liniare ale valorilor de intrare
- **Strat de ieșire**: produce rezultatul final (clasificare, valoare continuă etc.)

Un **neuron** calculează:

$z = \sum_{i=1}^n w_i x_i + b$

și apoi aplică o funcție de activare:
$y = f(z)$

#### Funcții de activare

- **Sigmoid**: $f(z) = \frac{1}{1 + e^{-z}}$ (utilizată în logistic regression)
- **ReLU**: $f(z) = \max(0, z)$ (rapidă și eficientă pentru rețele adânci)
- **Tanh**: $f(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}$
- **Softmax**: pentru clasificare multiclasa (normalizează ieșirile într-o distribuție de probabilitate)

#### Învățarea în RNA

- Se folosesc date etichetate (învățare supervizată)
- Se aplică algoritmul **Backpropagation** pentru a ajusta greutățile
- Optimizarea se face cu **Gradient Descent** (sau variante moderne: Adam, RMSprop)
#### Pașii antrenării:

1. **Forward pass** – se calculează ieșirea pentru un exemplu
2. **Calculul erorii** – diferența între ieșirea prezisă și valoarea reală
3. **Backward pass (backpropagation)** – se propagă eroarea înapoi și se calculează gradientul
4. **Actualizarea greutăților** – se aplică regula de învățare:
$w_j := w_j - \alpha \cdot \frac{\partial E}{\partial w_j}$

unde $\alpha$ este rata de învățare.

#### Probleme comune

- **Overfitting**: se învață prea bine datele de antrenament. Soluții:
    
    - Regularizare (L1/L2)
    - Dropout (oprirea aleatorie a unor neuroni în timpul antrenării)
    - Early stopping (oprirea timpurie a antrenării dacă eroarea pe setul de validare începe să crească)

#### Arhitecturi speciale

- **Perceptron simplu**: un singur strat de ieșire
- **Rețea multi-strat (MLP)**: unul sau mai multe straturi ascunse
- **CNN (Convolutional Neural Networks)**: pentru imagini
- **RNN (Recurrent Neural Networks)**: pentru secvențe (text, vorbire)

#### Aplicații

- Clasificare imagini (ex: recunoaștere cifre scrise de mână)
- Detectare obiecte în imagini
- Recunoaștere voce și traducere automată
- Generare de text (ex: ChatGPT)
- Jocuri (ex: AlphaGo)

**Avantaje**

- Pot învăța relații complexe și nelineare între date
- Foarte flexibile
- Performanță bună în multe domenii

**Dezavantaje**

- Necesită multe date pentru antrenare
- Pot fi dificil de interpretat (cutie neagră)
- Sensibile la hiperparametri (rata de învățare, arhitectura etc.)


##### Câte **straturi ascunse** folosim?

Nu există o regulă matematică fixă, dar următoarele principii te pot ghida:

- **1 strat ascuns** este adesea suficient pentru probleme simple sau când datele sunt aproape liniar separabile.
- **2–3 straturi ascunse** pot rezolva majoritatea problemelor nelineare uzuale.
- **>3 straturi** (deep learning) sunt utile pentru probleme complexe (imagini, text, audio), dar necesită mai multe date și resurse.

**Observație**: O rețea cu un singur strat ascuns poate aproxima orice funcție continuă (teorema aproximării universale), dar s-ar putea să aibă nevoie de foarte mulți neuroni, ceea ce nu este eficient.

##### Câți **neuroni pe strat**?

- Se aleg prin experimentare (validare încrucișată).
- Numărul ideal este un **compromis** între capacitatea de învățare și risc de overfitting.
- Reguli empirice:
    - între **dimensiunea inputului și outputului**
    - în general, între 10 și 100 de neuroni/strat pentru majoritatea aplicațiilor
    - poți începe cu dublul numărului de intrări și apoi ajustezi

##### Cum sunt inițializate greutățile (valori aleatorii)?

Fiecare conexiune dintre neuroni are un coeficient (greutate) $w_{ij}$ care este inițializat **aleator**, dar nu complet la întâmplare:

- Se folosesc **distribuții normale sau uniforme** cu medie zero.
- Scopul este să **evităm simetria** (toți neuronii începând identic → nu învață nimic diferit).
- Metode populare:
    - **Xavier Initialization** (Glorot): bună pentru funcții sigmoid/tanh
    - **He Initialization**: recomandată pentru ReLU
    - 
Exemplu pentru Xavier:

$w \sim \mathcal{U} \\left(-\\sqrt{\\frac{6}{n_{in} + n_{out}}}, \\sqrt{\\frac{6}{n_{in} + n_{out}}} \\right)$

unde $n_{in}$ = nr. neuroni intrare, $n_{out}$ = nr. neuroni ieșire.

#### Ordinea pașilor într-un ciclu de antrenare:

O rețea neuronală începe **întotdeauna** cu **forward propagation**.
1. **Forward propagation**:
    - Se introduc datele de intrare în rețea.
    - Se calculează activările neuronilor strat cu strat, până la ieșire.
    - Se obține **ieșirea rețelei**: $\hat{y}$.
    - Se compară această ieșire cu eticheta reală $y$ → se calculează **eroarea** (loss).
2. **Backward propagation (Backpropagation)**:
    - Se calculează gradientul funcției de cost față de fiecare parametru (greutate, bias).
    - Se aplică regula lanțului pentru a propaga eroarea înapoi prin rețea.
    - Se ajustează greutățile în direcția care **reduce eroarea** (folosind Gradient Descent).

**Intuiție:**

- **Forward pass** = „Ce spune rețeaua?"
- **Backward pass** = „Cât de greșit a spus-o și cum corectăm?”

