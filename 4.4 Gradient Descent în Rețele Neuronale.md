

Rețeaua neuronală învață **ajustând greutățile ($w$)** și **bias-urile ($b$)** pentru a **minimiza o funcție de eroare**.  
Aceasta măsoară diferența dintre valorile **prezise** de rețea și valorile **reale (etichetele)** din setul de antrenament.

Funcția de cost tipică pentru o problemă de regresie este eroarea pătratică medie:

$E = \frac{1}{m} \sum_{i=1}^{m} (y^{(i)} - \hat{y}^{(i)})^2$

unde:

- $m$ = număr de exemple de antrenament,
- $y^{(i)}$ = valoarea reală,
- $\hat{y}^{(i)}$ = valoarea prezisă.

Pentru clasificare, folosim **cross-entropy loss**:

$E = -\frac{1}{m} \sum_{i=1}^{m} \left[y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)})\right]$


#### Gradient Descent – Intuiție

Gradient Descent este o metodă de **optimizare**: vrea să găsească **minimul funcției de cost**.

Ideea: ne aflăm într-un spațiu al parametrilor (greutăți și bias-uri), iar funcția de cost este ca un relief. Gradientul ne spune **în ce direcție să mergem în jos** pentru a reduce eroarea.


#### Cum funcționează Gradient Descent?

Pentru fiecare parametru $w_j$ sau $b_j$:

$\text{Parametru nou} := \text{Parametru vechi} - \alpha \cdot \frac{\partial E}{\partial \text{Parametru}}$

unde:

- $\alpha$ este **rata de învățare** (learning rate),
- $\frac{\partial E}{\partial w_j}$ este **derivata funcției de eroare** față de $w_j$ – adică panta care ne spune cum să modificăm greutatea.

#### Backpropagation + Gradient Descent

Rețelele neuronale au mai multe straturi. Fiecare strat influențează eroarea totală.
Pentru a calcula cum să ajustăm fiecare greutate și bias, folosim:

1. **Forward pass** – calculăm ieșirea rețelei pentru un exemplu
2. **Calculăm eroarea totală**
3. **Backpropagation** – aplicăm regula lanțului (chain rule) pentru a calcula gradientul erorii față de fiecare parametru
4. **Gradient Descent** – actualizăm parametrii în direcția opusă gradientului

#### Actualizarea unei greutăți

Fie un neuron cu ieșire:

$\hat{y} = f\left(\sum_{i=1}^n w_i x_i + b\right)$

Actualizarea greutății $w_j$ se face astfel:

$w_j := w_j - \alpha \cdot \frac{\partial E}{\partial w_j}$

Iar derivata se calculează prin regula lanțului:

$\frac{\partial E}{\partial w_j} = \frac{\partial E}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z} \cdot \frac{\partial z}{\partial w_j}$

unde:

- $z = \sum w_i x_i + b$,
- $\frac{\partial z}{\partial w_j} = x_j$


#### Alegerea ratei de învățare $\alpha$

- **Prea mică**: învățarea e lentă.
- **Prea mare**: algoritmul sare peste minim și poate diverge.

În practică, se folosește o valoare între $0.001$ și $0.1$ și se ajustează empiric.


#### Variante moderne de Gradient Descent

- **Stochastic Gradient Descent (SGD)** – actualizează greutățile după fiecare exemplu
- **Mini-batch Gradient Descent** – actualizare pe loturi mici (ex: 32 exemple)
- **Optimizatori avansați**:
    - **Adam**: adaptează rata de învățare per parametru, convergență rapidă
    - **RMSprop**: bun pentru secvențe (RNN)
    - **Momentum**: adaugă „inerție” pentru a trece peste văi înguste
