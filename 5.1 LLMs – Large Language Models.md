#### 1. Elemente fundamentale în AI și Machine Learning

Pentru a construi un model AI de tip LLM (Large Language Model), sunt necesare trei componente fundamentale:

- Un **model/algoritm inteligent**
- **Date** în cantitate foarte mare
- **Putere de calcul** (GPU/TPU)

#### 2. Ce este un model LLM?

Un LLM este un model de rețea neuronală profundă antrenat pe cantități foarte mari de text pentru a înțelege și genera limbaj natural. Acesta poate efectua sarcini precum:

- Completarea automată a textului
- Traducerea între limbi
- Rezumarea documentelor
- Clasificarea propozițiilor
- Răspunsuri la întrebări

LLM-urile sunt, de obicei, modele **autoregresive**: ele prezic următorul cuvânt/token pe baza contextului anterior.

#### 3. Datele folosite pentru antrenare

LLM-urile învață din perechi de tip:

- Intrare (prompt): întrebarea sau fraza incompletă
- Ieșire (răspuns): continuarea/explicația/reformularea corectă

Exemple de seturi de date:

- Wikipedia
- Cărți
- Cod sursă (GitHub)
- Conversații (ex: StackExchange)
- Documentații tehnice

#### 4. Învățarea automată în LLM-uri

LLM-urile folosesc **învățare supervizată** și **învățare prin întărire**.

##### Pre-training (antrenarea inițială)

Scopul este învățarea structurii limbii. Sarcina principală este:

**Next-token prediction**: dat un șir de cuvinte $x_1, x_2, \dots, x_{t-1}$, se prezice $x_t$.

Se minimizează funcția de pierdere:

$L = -\sum_{t=1}^{T} \log P(x_t | x_1, \dots, x_{t-1})$

Aceasta se realizează pe seturi foarte mari de date.

##### ==Fine-tuning== (aliniere și specializare)

După pre-training, modelul este antrenat suplimentar pentru o sarcină specifică (ex: răspuns politicos, rezumare, cod etc.). În această etapă se folosesc date etichetate, relevante pentru domeniul dorit.


#### 5. Reinforcement Learning from Human Feedback (RLHF)

RLHF este o metodă de ajustare fină a comportamentului modelului pe baza preferințelor umane.

Pași:

1. Se generează mai multe răspunsuri pentru același prompt.
2. Un om le clasifică de la cel mai bun la cel mai slab.
3. Modelul învață să prefere răspunsurile apreciate de oameni.

Este folosit pentru a obține răspunsuri mai utile, mai sigure și mai naturale.


#### 6. Transformer și mecanismul Attention

##### Transformer

![[Pasted image 20250610222531.png]]

Arhitectura Transformer a fost introdusă în 2017 și a înlocuit complet rețelele recurente pentru procesarea textului.

Este bazată pe:

- Mecanismul de atenție (attention)
- Codificare pozițională (positional encoding)
- Procesare paralelă a tokenilor (fără recurență)

![[Pasted image 20250610222557.png]]
##### Attention

![[Pasted image 20250610222937.png]]

Atenția este un mecanism care decide **cât de mult contează fiecare cuvânt din context** atunci când prezicem următorul token.


Formula pentru scorul de atenție între două tokenuri:

$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V$

Unde:

- $Q$ = query
- $K$ = key
- $V$ = value
- $d_k$ = dimensiunea vectorului key

#### 7. Reprezentarea cuvintelor - embeddinguri

Tokenii (cuvinte, părți de cuvinte) sunt transformați în vectori densi, de dimensiune fixă.

Acești vectori sunt învățați în timpul pre-trainingului și capturează informații semantice și sintactice.


#### 8. Scalabilitatea LLM-urilor

LLM-urile moderne au:

- **Miliarde de parametri** (Greutăți ajustate în timpul învățării)
- **Milioane - miliarde de exemple** pentru antrenare
- **Zeci de layere transformer**

Parametrii sunt valorile interne învățate de model pentru a face predicții. Mai mulți parametri înseamnă mai multă capacitate de memorare și învățare, dar și risc mai mare de overfitting.
#### 9. Tipuri de sarcini pe care le pot rezolva LLM-urile

|Tip sarcină|Exemplu|
|---|---|
|Clasificare|Spam / non-spam|
|Generare|Scriere de eseuri, cod, rezumate|
|Traducere|„Bonjour” → „Bună ziua”|
|Răspunsuri la întrebări|„Ce este RLHF?”|
|Completare|„Astăzi am fost la...” → „bibliotecă”|
|Conversație|Chat între om și model|

#### 10. Limitări și pericole

LLM-urile pot avea comportamente nedorite:

- **Halucinații**: modelul „inventează” informații false
- **Bias**: reflectă prejudecăți din datele de antrenament
- **Dezinformare**: pot produce texte convingătoare dar incorecte
- **Lipsa memoriei**: nu pot păstra context pe termen lung fără arhitecturi speciale
- **Comportament nedeterminist**: același prompt poate genera răspunsuri diferite

#### 11. Ce urmează în dezvoltarea LLM-urilor?

- **LLM-uri multimodale**: lucrează cu text, imagine, video, sunet
- **Memorie extinsă**: capacitate de a reține conversații lungi
- **Agenți autonomi**: modele care pot lua decizii, planifica, acționa
- **Raționament simbolic și logic**: integrarea gândirii structurate
- **Fine-tuning personalizat**: modele adaptate nevoilor fiecărui utilizator