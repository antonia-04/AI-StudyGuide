
O **Convolutional Neural Network** este un tip special de rețea neuronală artificială, creată pentru a prelucra date cu structură spațială – cum ar fi imaginile.

Spre deosebire de rețelele complet conectate (MLP), care tratează datele ca vectori, CNN-urile pot **înțelege poziția și vecinătatea** elementelor din imagine (de exemplu, unde sunt ochii într-o față).


#### De ce sunt eficiente CNN-urile pentru imagini?

1. **Localitate**: fiecare neuron „vede” doar o regiune mică a imaginii
2. **Partajarea greutăților**: același filtru este aplicat pe toată imaginea
3. **Reducerea dimensiunii**: prin pooling, se obține o reprezentare mai compactă
4. **Extracție automată de caracteristici**: CNN-urile învață singure ce este relevant


### Straturile unei CNN

#### 1. Strat convoluțional

Este componenta esențială a unei CNN.

Aplică un **filtru** (kernel) pe regiuni mici din imagine pentru a detecta caracteristici locale. Filtrul este o matrice de greutăți care „scanează” imaginea.

Fie o imagine $I$ și un kernel $K$, ieșirea convoluției este:

$S(i, j) = \sum_m \sum_n I(i + m, j + n) \cdot K(m, n)$

Această operație produce o **hartă de activare (feature map)** care evidențiază unde apare un tipar detectat de acel kernel.

> Un CNN poate avea mai multe filtre, fiecare învățând un tipar diferit (ex: margini verticale, texturi, colțuri etc.)


#### 2. Filtre (Kerneluri)

- Un **filtru** este o matrice mică de greutăți, ex: $3 \times 3$, $5 \times 5$
- Este inițializat cu valori aleatoare și este antrenat împreună cu rețeaua
- Se aplică pe întreaga imagine prin **translație**, pentru a detecta caracteristici similare în diferite regiuni

**Fiecare filtru generează o hartă de activare diferită.**
Dacă stratul convoluțional are 32 de filtre, rezultă 32 de hărți de activare.


#### 3. Funcție de activare (ReLU)

După aplicarea filtrului, se aplică de obicei funcția:

$f(z) = \max(0, z)$

Aceasta elimină valorile negative și introduce nelinearitate.

#### 4. Strat de pooling

**Pooling-ul** reduce dimensiunea hărților de activare și păstrează informația esențială.

Există mai multe tipuri:

- **Max pooling**: selectează valoarea maximă din fiecare fereastră locală
- **Average pooling**: calculează media

Exemplu: pentru o hartă $4 \times 4$, max pooling cu fereastră $2 \times 2$ și pas 2 returnează o matrice $2 \times 2$.

Pooling-ul aduce:

- Reducerea dimensionalității (mai puțini parametri)
- Toleranță la translații mici în imagine
- Previne overfitting


#### 5. Straturi complet conectate

După extragerea caracteristicilor cu convoluții și pooling, acestea sunt „aplatizate” (reshape în vector) și trecute prin unul sau mai multe **dense layers**.

Ieșirea finală este:

- o valoare scalară (pentru regresie)
- sau un vector de probabilități (cu softmax)

### Arhitectura tipică CNN

1. Intrare: imagine (ex: $28 \times 28$ pixeli)
2. Convoluție + activare ReLU
3. Pooling
4. (Repetare Convoluție + Pooling de câteva ori)
5. Flatten
6. Dense layers
7. Strat de ieșire

#### Dimensiunea ieșirii după convoluție

Fie:

- imagine de intrare cu dimensiune $W$
- kernel de dimensiune $F$
- padding $P$
- pas (stride) $S$

Atunci dimensiunea ieșirii este:

$\frac{W - F + 2P}{S} + 1$


#### Exemplu complet

Imagine $6 \times 6$, kernel $3 \times 3$, padding $0$, stride $1$:

$\frac{6 - 3 + 0}{1} + 1 = 4$

Ieșirea este o matrice $4 \times 4$

#### Aplicații CNN

- Clasificare de imagini
- Detectare obiecte (ex: YOLO, SSD)
- Recunoaștere facială
- Segmentare semantică (ex: auto-driving)
- Clasificare medicală (ex: tumori în imagini)
- Procesare video (ex: recunoaștere de acțiuni)



#### Ce este o **convoluție**?

În contextul **CNN**, o _convoluție_ este o **operație matematică** care combină două funcții (sau două matrice în cazul imaginilor) pentru a obține o nouă funcție (sau o nouă matrice), care evidențiază caracteristici importante din date.

**În practică:**

CNN-urile folosesc **convoluția între o imagine și un filtru (kernel)** pentru a extrage tipare locale (colțuri, margini, texturi etc.).


##### Formula generală (pentru imagini 2D):

Fie:

- o imagine de intrare $I$
- un kernel (filtru) $K$ de dimensiune mică (ex: $3 \times 3$)

Operația de convoluție produce o ieșire $S(i, j)$:

$S(i, j) = \sum_{m=0}^{f-1} \sum_{n=0}^{f-1} I(i + m, j + n) \cdot K(m, n)$

unde:

- $f$ este dimensiunea filtrului (de obicei $3$ sau $5$)
- $(i, j)$ este poziția în imagine unde se aplică filtrul

##### Intuiție

Imaginează-ți că ai o **fereastră mică (filtrul)** care alunecă peste imagine. La fiecare pas, face un **produs scalar** între valorile din fereastră și valorile din filtru, apoi pune rezultatul într-o nouă imagine.

##### Exemplu numeric simplu

Imagine $I$:

```
1 2 0
0 1 3
2 1 1
```

Kernel $K$ (detecție margini):

```
1 0
0 -1
```

Convoluția se aplică glisând filtrul peste imagine. Se înmulțesc valorile element cu element și se însumează.
##### De ce este importantă convoluția?

- Detectează **caracteristici locale**, indiferent unde apar în imagine
- Permite **partajarea greutăților** (același kernel se aplică pe toată imaginea)
- Reduce semnificativ **numărul de parametri** comparativ cu rețelele complet conectate

##### Observații

- În practică, multe framework-uri folosesc de fapt **cross-correlation**, nu convoluție strict matematică (dar rezultatul este similar)
- Se pot adăuga și:
    - **padding** – completarea marginii imaginii cu 0
    - **stride** – pasul cu care se deplasează filtrul

![[Pasted image 20250610220032.png]]