

**Metoda Gradient Descent** este o tehnică folosită pentru **optimizarea** parametrilor unui model, precum coeficienții unei regresii. Scopul este de a **minimiza eroarea** modelului, găsind valorile optimale ale coeficientului $\beta$.

Presupunem că avem:

- Date de intrare $x \in \mathbb{R}^d$
- Date de ieșire $y \in \mathbb{R}$

Se dorește să construim un **model liniar** $f(x)$ care transformă $x$ în $y$. Modelul este definit astfel:

$f(x) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_d x_d$

Aceasta este o problemă de **învățare supervizată**, în care obiectivul este de a găsi valorile coeficientului $\beta$ care minimizează **eroarea** modelului.

#### **Funcția de cost (Loss Function)**

Funcția de cost $L$ măsoară diferența între valorile prezise și valorile reale ale ieșirii. Eroarea se poate exprima astfel:

$L = \sum_{i=1}^{n} (y_i - f(x_i))^2$

Scopul este să minimizăm această funcție pentru a obține valorile optime ale coeficientului $\beta$.

#### **Algoritmul Gradient Descent**

În cadrul **metodei Gradient Descent**, coeficienții $\beta$ sunt actualizați în mod iterativ pentru a minimiza eroarea. La fiecare iterație, coeficientul $\beta_k$ (pentru fiecare caracteristică $x_k$) se ajustează astfel:

$\beta_k(t+1) = \beta_k(t) - \text{learning\_rate} \times \text{error}(t) \times x_k$

Pentru termenul de bias $\beta_0$, actualizarea este:

$\beta_0(t+1) = \beta_0(t) - \text{learning\_rate} \times \text{error}(t)$

Unde:

- $\text{error}(t) = f(x_t) - y_t$ este eroarea la iterația $t$
- $f(x_t)$ este valoarea prezisă de modelul la iterația $t$
- $y_t$ este valoarea reală (output-ul dorit)

####  **Tipuri de Gradient Descent**


În **Învățarea Automată (Machine Learning)**, **Gradient Descent** este o metodă folosită pentru a optimiza un model (de exemplu, un model de regresie sau un rețea neurală). Scopul este să găsim parametrii modelului care minimizează eroarea între ceea ce prezicem și ceea ce ar trebui să prezicem (adică, valoarea reală).

Gradient Descent are mai multe variante,  trei dintre ele:

1. **Stochastic Gradient Descent (SGD)**
2. **Batch Gradient Descent (BGD)**
3. **Mini-Batch Gradient Descent**
![[Pasted image 20250609210713.png]]

##### 1. **Stochastic Gradient Descent (SGD)**

**Cum funcționează**:

- În **Stochastic Gradient Descent**, modelul este **actualizat** imediat după ce procesează fiecare **exemplu individual** de antrenament.
- În loc să calculeze eroarea pentru **întregul set de date**, modelul face o actualizare pentru fiecare exemplu (de exemplu, fiecare imagine, fiecare document text, etc.).
**Formulă**:

- $\beta_k(t+1) = \beta_k(t) - {learning_rate} \times \text{error}(t) \times x_k$
- Aici:
    - $\beta_k(t)$ reprezintă coeficientul curent al modelului (parametrii pe care încercăm să îi optimizăm).
    - ${learning_rate}$ este un factor care determină cât de mari sunt actualizările.
    - ${error}(t)$ este eroarea calculată pentru exemplul curent.
    - $x_k$ este exemplul curent.

**Exemplu simplu**:  
Imaginați-vă că vrem să învățăm un model care predice prețul caselor bazat pe suprafața acestora. Fiecare casă reprezintă un exemplu de antrenament. În **SGD**, procesul ar fi:

1. Introducem datele pentru prima casă (exemplu de antrenament).
2. Calculăm eroarea (diferența dintre prețul prezis și prețul real).
3. Actualizăm parametrii modelului pe baza acelei erori.
4. Trebuie să repetăm acest proces pentru fiecare casă din setul de date, de fiecare dată actualizând parametrii modelului.

**Cum se resimte?**:

- Viteza este rapidă, dar actualizările sunt **mai zgomotoase** sau imprecise (pentru că folosim doar un exemplu pentru a ajusta parametrii). Modelul poate oscila mult înainte de a găsi valoarea optimă a parametrilor.

##### 2. **Batch Gradient Descent (BGD)**

**Cum funcționează**:

- În **Batch Gradient Descent**, modelul este **actualizat** doar după ce **toate exemplele de antrenament** au fost procesate.
- Calculăm eroarea pentru **întregul set de date** și abia apoi facem actualizarea modelului.
**Formulă**:
- $\beta = (X^T X)^{-1} X^T y$
- Aici:
    - $X$ este matricea datelor de intrare.
    - $y$ este vectorul valorilor reale.
    - $\beta$ reprezintă parametrii modelului pe care îi căutăm.

**Exemplu simplu**:  
Imaginați-vă același exemplu cu casele. În **BGD**, procesul ar fi:

1. Introducem datele pentru **toate casele** din setul de date.
2. Calculăm eroarea medie pentru întreaga listă de case.
3. După ce am procesat **toate datele**, actualizăm modelul o singură dată, pe baza erorii medii.

**Cum se resimte?**:

- Este mai **stabil** decât SGD, pentru că folosim toată informația pentru actualizare, dar este mult mai lent, pentru că trebuie să procesăm tot setul de date înainte de a face orice actualizare a modelului.

##### 3. **Mini-Batch Gradient Descent**

**Cum funcționează**:

- În **Mini-Batch Gradient Descent**, setul de date este împărțit în **mini-batch-uri**, adică grupuri mai mici de exemple.
- Modelul este actualizat **după procesarea fiecărui mini-batch**.

**Exemplu simplu**:  
Imaginați-vă că aveți setul de date cu 1000 de case:

1. Împărțiți cele 1000 de case în grupuri mai mici de 50.
2. Pentru fiecare grup (mini-batch), procesăm datele și actualizăm modelul pe baza erorii calculate pentru acel mini-batch.
3. După ce am procesat toate grupurile, am terminat o **epocă**.

**Cum se resimte?**:

- Este **un compromis** între **SGD** și **BGD**:
    
    - Este mai rapid decât **BGD** pentru că procesăm datele în grupuri mici, nu în întregul set.
    - Este mai stabil decât **SGD** pentru că folosim mai multe exemple pentru a face o actualizare, dar nu toate.


##### **Recapitulare**:

- **SGD**: Actualizare rapidă, dar imprecisă pentru fiecare exemplu. Poate oscila mult înainte de a găsi o soluție optimă.
- **BGD**: Actualizare stabilă, dar lentă, pentru întregul set de date.
- **Mini-Batch**: Compromis între rapiditate și stabilitate, folosind grupuri mici de date pentru actualizare.

### **Imaginează-ți că ai un set de date cu imagini**:

- **SGD**: Vei actualiza modelul de fiecare dată când procesezi o imagine (exemplu de antrenament).
- **BGD**: Vei procesa toate imaginile și apoi vei actualiza modelul.
- **Mini-Batch**: Vei împărți imaginile în grupuri mai mici și vei actualiza modelul după fiecare grup.

##### **Diferențe esențiale**:

1. **Viteză**:
    - **SGD** este cel mai rapid pentru că face o actualizare după fiecare exemplu.
    - **BGD** este cel mai lent pentru că face actualizarea doar după procesarea întregului set de date.
    - **Mini-Batch** este un compromis între cele două, fiind mai rapid decât **BGD** și mai stabil decât **SGD**.
2. **Stabilitate**:
    - **SGD** poate fi imprecis și instabil, având oscilații mari.
    - **BGD** este foarte stabil, dar lent.
    - **Mini-Batch** aduce un echilibru între cele două, având un comportament mai stabil decât **SGD** și o viteză mai mare decât **BGD**.

#### **Scopul și Importanța Metodei**

Metoda Gradient Descent ajută la găsirea celor mai bune parametri pentru un model de regresie printr-un proces iterativ. Alegerea tipului de Gradient Descent depinde de dimensiunea datelor și de timpul de antrenare.