Majoritatea modelelor de ML procesează doar **numere**. Orice tip de date (text, imagine, audio) trebuie transformat numeric.
#### Funcții matematice – exemple

Funcțiile matematice sunt fundamentale în ML:

- Funcție cu un singur parametru și un singur rezultat:  
    $f\colon \mathbb{R} \to \mathbb{R}$  
    $f(x)=x^2+2x+1\quad f(3)=16$
    
- Funcție cu doi parametri și un singur rezultat:  
    $f\colon \mathbb{R}^2 \to \mathbb{R}$  
    $f(x,y)=x^2+y^2+xy\quad f(2,3)=19$
    
- Funcție cu un singur parametru și mai multe rezultate:  
    $f\colon \mathbb{R} \to \mathbb{R}^2$  
    $f(x)=(x^3+3,; x-4)\quad f(2)=(11,-2)$
    
- Funcție generală cu mai mulți parametri și mai multe rezultate:  
    $f\colon \mathbb{R}^n\to\mathbb{R}^k$  
    $f(x_1,\dots,x_n)=(f_1(x_1,\dots,x_n),\dots,f_k(x_1,\dots,x_n))$
    

Un model ML este exact acest tip de funcție: primește numerice și returnează numerice, care pot fi interpretate ulterior.

#### Exemple de rețea neuronală

O rețea neuronală este un algoritm care ia un vector numeric $x\in\mathbb{R}^n$ și returnează un vector numeric în $\mathbb{R}^m$, utilizând:

- $p$ **weights**, vector $w=[w_1,\dots,w_p]$
- $q$ **biases**, vector $b=[b_1,\dots,b_q]$
- O funcție de arhitectură $f_{\text{arc}}:\mathbb{R}^{n+p+q}\to\mathbb{R}^m$
- O funcție de **cost** (loss): $\text{loss}:\mathbb{R}^m\times\mathbb{R}^m\to\mathbb{R}$

În pseudocod:

```
predict(x):
    return f_arc(x, w, b)

train(x, y):
    pred = f_arc(x, w, b)
    L = loss(pred, y)
    calculezi ∂L/∂w_i și ∂L/∂b_j
    actualizezi w,b cu gradient descent
```


#### Reprezentarea imaginilor

O imagine este o matrice de pixeli:

- Alb-negru: o singură intensitate [0,255]
- Color: RGB, trei intensități [0,255] per pixel

Exemplu: o imagine de $13\times 13$ are $169$ pixeli, deci $169\times 3 =507$ valori.  
O imagine de $1024\times 1024$ are $1024^2=1{,}048{,}576$ pixeli → $3\times1{,}048{,}576=3{,}145{,}728$ valori.

Astfel modelul matematic al unui generator de imagini (ex: DALL·E):

$f(\dots)=(y_1,y_2,\dots,y_{3\,145\,728})$

#### Reprezentarea textului

Textul trebuie transformat numeric, dar menținând relații semantice:

- Indexare simplă: cuvânt→indice → nu păstrează semantica
- Soluție: **embedding-uri** – vectori densi aflați prin ML

Exemplu:

$\text{Emb}(\text{"word"})=(x_1,x_2,\dots,x_k)$

Embedding-urile reflectă relații: diferența vectorială între „king” și „queen” este similară cu diferența între „man” și „woman”.


#### Tokenizare și secvențe

Pentru propoziții de lungime variabilă:

1. Se împarte textul în **tokeni** (ex: cuvinte, subcuvinte)
2. Se atribuie embedding fiecărui token
3. Se obțin vectori $(x_{1,1\dots k},\dots,x_{q,1\dots k})$

#### Modelul complet pentru generare imagini din text

1. $z_1,\dots,z_p = \text{generateRandomNumbers()}$
2. $t_1,\dots,t_q = \text{Tokenize(text)}$
3. $(x_{1,1..k},\dots,x_{q,1..k}) = \text{map(Emb, tokens)}$
4. $(y_1,\dots,y_k)=f(x_{1,1..k},\dots,x_{q,1..k},z_1,\dots,z_p)$
5. $\text{image} = \text{imageFromVector}(y_1,\dots,y_k)$

Unde:

- `generateRandomNumbers()` produce vectorul latent $z$
- `Tokenize()`,`Emb()`,`imageFromVector()` sunt deja implementări existente
- `f` este funcția dificil de găsit (modelul antrenat)

#### Rolul spațiului latent

Adăugând un vector aleator $z$, obținem rezultate diferite la fiecare execuție. Modelul este **funcție continuă**, deci varii mici în $z$ determină variații mici în imagine.

Spațiul latent controlează aspecte vizuale: culori, poziție, stil.


#### Concepte-cheie:

- ML lucrează doar cu numere → avem nevoie de reprezentări numerice
- Modelele ML sunt funcții matematice pure, care trebuie învățate
- Reprezentările numerice de calitate păstrează relații utile (semantice, vizuale)
- Embedding-urile și spațiul latent permit generativitate și control asupra output-ului
