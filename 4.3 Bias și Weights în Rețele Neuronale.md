
##### **Weights (W) – Greutățile**
- **Ce sunt?**  
  - Parametrii pe care rețeaua neuronală **îi înmulțește** cu input-urile.  
  - Determină **cât de mult contribuie** fiecare intrare la ieșire.  
- **Unde se aplică?**  
  - La fiecare conexiune între neuroni (strat → strat).  

##### **Bias (b) – Părtinirea**  
- **Ce este?**  
  - Un parametru **adăugat** după operația de înmulțire (`W · X`).  
  - Permite rețelei să **translateze** funcția de activare.  
- **De ce e necesar?**  
  - Fără bias, orice transformare ar trebui să treacă prin origine (`0,0`), limitând capacitatea modelului.  


#### **Reprezentarea Matematică**
##### **Pentru un singur neuron**  
Dacă avem:  
- **Input:** `X = [x₁, x₂, ..., xₙ]`  
- **Weights:** `W = [w₁, w₂, ..., wₙ]`  
- **Bias:** `b` (scalar)  

**Ieșirea brută (z):**  
$$
z = w_1 x_1 + w_2 x_2 + \dots + w_n x_n + b = \sum_{i=1}^n w_i x_i + b
$$  
sau în formă vectorială:  
$$
z = W^T X + b
$$

**Ieșirea după activare (`a`):**  
$$
a = \sigma(z) = \sigma(W^T X + b)
$$  
unde `σ` este funcția de activare (e.g., *ReLU*, *Sigmoid*).  


#### **Într-un Strat (Layer) al Rețelei**
Pentru un strat cu `m` neuroni și `n` intrări:  
- **Weights** devine o **matrice** `W ∈ ℝ^(n×m)`  
- **Bias** devine un **vector** `b ∈ ℝ^m`  

**Calculul pentru întreg stratul:**  
$$
Z = X W + b  
$$  
$$
A = \sigma(Z)
$$  
unde:  
- `X ∈ ℝ^(batch_size × n)` (input)  
- `W ∈ ℝ^(n × m)` (weights)  
- `b ∈ ℝ^m` (bias)  
- `Z, A ∈ ℝ^(batch_size × m)` (ieșire brută și activată)  


## **Rolul lor în Antrenare**
##### **Actualizarea prin Backpropagation**
La fiecare pas, se ajustează `W` și `b` folosind gradient descent:  
1. **Calcul gradient pentru weights:**  
   $$
   \frac{\partial \mathcal{L}}{\partial W} = \frac{\partial \mathcal{L}}{\partial Z} \cdot X^T
   $$  
2. **Calcul gradient pentru bias:**  
   $$
   \frac{\partial \mathcal{L}}{\partial b} = \sum \frac{\partial \mathcal{L}}{\partial Z}
   $$  
3. **Actualizare:**  
   $$
   W = W - \alpha \frac{\partial \mathcal{L}}{\partial W}
   $$  
   $$
   b = b - \alpha \frac{\partial \mathcal{L}}{\partial b}
   $$  
   (unde `α` este rata de învățare)  


##### **Interpretare Geometrică**
| Componentă | Efect Geometric | Exemplu |
|------------|----------------|---------|
| **Weights** | Rotire și scalare a hiperplanului de decizie | Schimbă panta dreptei `y = w·x + b` |
| **Bias** | Translație (deplasare pe axa verticală) | Mută dreapta `y = w·x` în sus/jos cu `b` |


##### **Concluzie**
- **Weights (W)** = Ce înmulțește input-urile (controlez contribuția fiecărui feature).  
- **Bias (b)** = Ce se adaugă după (permite deplasarea funcției).  
- **Formula generală** pentru un neuron:  
  $$
  \text{output} = \sigma\left( \sum_{i} w_i x_i + b \right)
  $$  
- În backpropagation, ambele se actualizează pentru a minimiza eroarea (`ℒ`).